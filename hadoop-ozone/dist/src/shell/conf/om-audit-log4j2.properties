#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements. See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License. You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
name=PropertiesConfig

# Checks for config change periodically and reloads
monitorInterval=30

filter=read,write
# filter.read.onMatch=DENY avoids logging all READ events
# filter.read.onMatch=ACCEPT permits logging all READ events
# The above two settings ignore the log levels in configuration
# filter.read.onMatch=NEUTRAL permits logging of only those READ events
# which are attempted at log level equal or greater than log level specified
# in the configuration
filter.read.type=MarkerFilter
filter.read.marker=READ
filter.read.onMatch=NEUTRAL
filter.read.onMismatch=NEUTRAL

# filter.write.onMatch=DENY avoids logging all WRITE events
# filter.write.onMatch=ACCEPT permits logging all WRITE events
# The above two settings ignore the log levels in configuration
# filter.write.onMatch=NEUTRAL permits logging of only those WRITE events
# which are attempted at log level equal or greater than log level specified
# in the configuration
filter.write.type=MarkerFilter
filter.write.marker=WRITE
filter.write.onMatch=NEUTRAL
filter.write.onMismatch=NEUTRAL

# Log Levels are organized from most specific to least:
# OFF (most specific, no logging)
# FATAL (most specific, little data)
# ERROR
# WARN
# INFO
# DEBUG
# TRACE (least specific, a lot of data)
# ALL (least specific, all data)

# Uncomment following section to enable logging to console appender also
#appenders=console, rolling
#appender.console.type=Console
#appender.console.name=STDOUT
#appender.console.layout.type=PatternLayout
#appender.console.layout.pattern=%d{DEFAULT} | %-5level | %c{1} | %msg | %throwable{3} %n

# Comment this line when using both console and rolling appenders
appenders=rolling,sysrolling

# Rolling File Appender with size & time thresholds.
# Rolling is triggered when either threshold is breached.
# The rolled over file is compressed by default
# Time interval is specified in seconds 86400s=1 day
# Audit files under the base directory that are 30 days old
# or older are deleted at rollover time
appender.rolling.type=RollingFile
appender.rolling.name=RollingFile
appender.rolling.fileName =${sys:hadoop.log.dir}/om-audit-${hostName}.log
appender.rolling.filePattern=${sys:hadoop.log.dir}/om-audit-${hostName}-%d{yyyy-MM-dd}-%i.log.gz
appender.rolling.layout.type=PatternLayout
appender.rolling.layout.pattern=%d{DEFAULT} | %-5level | %c{1} | %msg | %throwable{3} %n
appender.rolling.policies.type=Policies
appender.rolling.policies.time.type=TimeBasedTriggeringPolicy
appender.rolling.policies.time.interval=1
appender.rolling.policies.size.type=SizeBasedTriggeringPolicy
appender.rolling.policies.size.size=64MB
appender.rolling.strategy.type=DefaultRolloverStrategy
appender.rolling.strategy.max=3000
appender.rolling.strategy.delete.type=Delete
appender.rolling.strategy.delete.basePath=${sys:hadoop.log.dir}
appender.rolling.strategy.delete.maxDepth=1
appender.rolling.strategy.delete.ifFileName.type=IfFileName
appender.rolling.strategy.delete.ifFileName.glob=om-audit-*.log.gz
appender.rolling.strategy.delete.ifLastModified.type=IfLastModified
appender.rolling.strategy.delete.ifLastModified.age=30d

appender.sysrolling.type=RollingFile
appender.sysrolling.name=SysRollingFile
appender.sysrolling.fileName =${sys:hadoop.log.dir}/om-sys-audit-${hostName}.log
appender.sysrolling.filePattern=${sys:hadoop.log.dir}/om-sys-audit-${hostName}-%d{yyyy-MM-dd}-%i.log.gz
appender.sysrolling.layout.type=PatternLayout
appender.sysrolling.layout.pattern=%d{DEFAULT} | %-5level | %c{1} | %msg | %throwable{3} %n
appender.sysrolling.policies.type=Policies
appender.sysrolling.policies.time.type=TimeBasedTriggeringPolicy
appender.sysrolling.policies.time.interval=1
appender.sysrolling.policies.size.type=SizeBasedTriggeringPolicy
appender.sysrolling.policies.size.size=64MB
appender.sysrolling.strategy.type=DefaultRolloverStrategy
appender.sysrolling.strategy.max=3000
appender.sysrolling.strategy.delete.type=Delete
appender.sysrolling.strategy.delete.basePath=${sys:hadoop.log.dir}
appender.sysrolling.strategy.delete.maxDepth=1
appender.sysrolling.strategy.delete.ifFileName.type=IfFileName
appender.sysrolling.strategy.delete.ifFileName.glob=om-sys-audit-*.log.gz
appender.sysrolling.strategy.delete.ifLastModified.type=IfLastModified
appender.sysrolling.strategy.delete.ifLastModified.age=30d

loggers=audit,sysaudit
logger.audit.name=OMAudit
logger.audit.level=INFO
logger.audit.appenderRefs=rolling
logger.audit.appenderRef.file.ref=RollingFile

logger.sysaudit.name=OMSystemAudit
logger.sysaudit.level=INFO
logger.sysaudit.appenderRefs=sysrolling
logger.sysaudit.appenderRef.file.ref=SysRollingFile

rootLogger.level=INFO
#rootLogger.appenderRefs=stdout
#rootLogger.appenderRef.stdout.ref=STDOUT
