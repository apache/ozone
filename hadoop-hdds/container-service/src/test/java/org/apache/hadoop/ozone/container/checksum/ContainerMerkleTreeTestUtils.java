/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License. You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.hadoop.ozone.container.checksum;

import static org.apache.hadoop.ozone.container.checksum.ContainerChecksumTreeManager.getContainerChecksumFile;
import static org.junit.jupiter.api.Assertions.assertEquals;
import static org.junit.jupiter.api.Assertions.assertNotNull;
import static org.junit.jupiter.api.Assertions.assertTrue;

import java.io.File;
import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.nio.ByteBuffer;
import java.nio.file.Files;
import java.util.Arrays;
import java.util.Comparator;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Random;
import java.util.Set;
import java.util.stream.Collectors;
import org.apache.commons.lang3.tuple.Pair;
import org.apache.hadoop.hdds.conf.ConfigurationSource;
import org.apache.hadoop.hdds.conf.StorageUnit;
import org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos;
import org.apache.hadoop.hdds.scm.OzoneClientConfig;
import org.apache.hadoop.hdds.scm.ScmConfigKeys;
import org.apache.hadoop.ozone.HddsDatanodeService;
import org.apache.hadoop.ozone.container.common.impl.ContainerData;
import org.apache.hadoop.ozone.container.common.interfaces.Container;
import org.apache.hadoop.ozone.container.ozoneimpl.OzoneContainer;
import org.apache.ratis.thirdparty.com.google.protobuf.ByteString;

/**
 * Helper methods for testing container checksum tree files and container reconciliation.
 */
public final class ContainerMerkleTreeTestUtils {
  private ContainerMerkleTreeTestUtils() {
  }

  public static void assertTreesSortedAndMatch(ContainerProtos.ContainerMerkleTree expectedTree,
                                               ContainerProtos.ContainerMerkleTree actualTree) {
    assertEquals(expectedTree.getDataChecksum(), actualTree.getDataChecksum());
    assertEquals(expectedTree.getBlockMerkleTreeCount(), actualTree.getBlockMerkleTreeCount());

    long prevBlockID = -1;
    for (int blockIndex = 0; blockIndex < expectedTree.getBlockMerkleTreeCount(); blockIndex++) {
      ContainerProtos.BlockMerkleTree expectedBlockTree = expectedTree.getBlockMerkleTree(blockIndex);
      ContainerProtos.BlockMerkleTree actualBlockTree = actualTree.getBlockMerkleTree(blockIndex);

      // Blocks should be sorted by block ID.
      long currentBlockID = actualBlockTree.getBlockID();
      assertTrue(prevBlockID < currentBlockID);
      prevBlockID = currentBlockID;

      assertEquals(expectedBlockTree.getBlockID(), actualBlockTree.getBlockID());
      assertEquals(expectedBlockTree.getDataChecksum(), actualBlockTree.getDataChecksum());

      long prevChunkOffset = -1;
      for (int chunkIndex = 0; chunkIndex < expectedBlockTree.getChunkMerkleTreeCount(); chunkIndex++) {
        ContainerProtos.ChunkMerkleTree expectedChunkTree = expectedBlockTree.getChunkMerkleTree(chunkIndex);
        ContainerProtos.ChunkMerkleTree actualChunkTree = actualBlockTree.getChunkMerkleTree(chunkIndex);

        // Chunks should be sorted by offset.
        long currentChunkOffset = actualChunkTree.getOffset();
        assertTrue(prevChunkOffset < currentChunkOffset);
        prevChunkOffset = currentChunkOffset;

        assertEquals(expectedChunkTree.getOffset(), actualChunkTree.getOffset());
        assertEquals(expectedChunkTree.getLength(), actualChunkTree.getLength());
        assertEquals(expectedChunkTree.getDataChecksum(), actualChunkTree.getDataChecksum());
        assertEquals(expectedChunkTree.getChecksumMatches(), actualChunkTree.getChecksumMatches());
      }
    }
  }

  /**
   * Builds a ChunkInfo object using the provided information. No new checksums are calculated, so this can be used
   * as either the leaves of pre-computed merkle trees that serve as expected values, or as building blocks to pass
   * to ContainerMerkleTree to have it build the whole tree from this information.
   *
   * @param indexInBlock   Which chunk number within a block this is. The chunk's offset is automatically calculated
   *                       from this based on a fixed length.
   * @param chunkChecksums The checksums within the chunk. Each is assumed to apply to a fixed value
   *                       "bytesPerChecksum" amount of data and are assumed to be contiguous.
   * @return The ChunkInfo proto object built from this information.
   */
  public static ContainerProtos.ChunkInfo buildChunk(ConfigurationSource config, int indexInBlock,
                                                     ByteBuffer... chunkChecksums) {
    final long chunkSize = (long) config.getStorageSize(
        ScmConfigKeys.OZONE_SCM_CHUNK_SIZE_KEY, ScmConfigKeys.OZONE_SCM_CHUNK_SIZE_DEFAULT, StorageUnit.BYTES);
    final int bytesPerChecksum = config.getObject(OzoneClientConfig.class).getBytesPerChecksum();

    // Each chunk checksum is added under the same ChecksumData object.
    ContainerProtos.ChecksumData checksumData = ContainerProtos.ChecksumData.newBuilder()
        .setType(ContainerProtos.ChecksumType.CRC32)
        .setBytesPerChecksum(bytesPerChecksum)
        .addAllChecksums(Arrays.stream(chunkChecksums)
            .map(ByteString::copyFrom)
            .collect(Collectors.toList()))
        .build();

    return ContainerProtos.ChunkInfo.newBuilder()
        .setChecksumData(checksumData)
        .setChunkName("chunk")
        .setOffset(indexInBlock)
        .setLen(chunkSize)
        .build();
  }

  /**
   * This reads the checksum file for a container from the disk without synchronization/coordination between readers
   * and writers within a datanode.
   */
  public static ContainerProtos.ContainerChecksumInfo readChecksumFile(ContainerData data) throws IOException {
    try (InputStream inStream = Files.newInputStream(getContainerChecksumFile(data).toPath())) {
      return ContainerProtos.ContainerChecksumInfo.parseFrom(inStream);
    }
  }

  /**
   * Builds a {@link ContainerMerkleTreeWriter} representing arbitrary data. This can be used to test that the same
   * structure is preserved throughout serialization, deserialization, and API calls.
   */
  public static ContainerMerkleTreeWriter buildTestTree(ConfigurationSource conf) {
    return buildTestTree(conf, 5);
  }

  public static ContainerMerkleTreeWriter buildTestTree(ConfigurationSource conf, int numBlocks) {
    ContainerMerkleTreeWriter tree = new ContainerMerkleTreeWriter();
    byte byteValue = 1;
    for (int blockIndex = 1; blockIndex <= numBlocks; blockIndex++) {
      for (int chunkIndex = 0; chunkIndex < 4; chunkIndex++) {
        tree.addChunks(blockIndex, true,
            buildChunk(conf, chunkIndex, ByteBuffer.wrap(new byte[]{byteValue++, byteValue++, byteValue++})));
      }
    }
    return tree;
  }

  /**
   * Returns a Pair of merkle tree and the expected container diff for that merkle tree.
   */
  public static Pair<ContainerProtos.ContainerMerkleTree, ContainerDiffReport>
      buildTestTreeWithMismatches(ContainerMerkleTreeWriter originalTree, int numMissingBlocks, int numMissingChunks,
                                  int numCorruptChunks) {

    ContainerProtos.ContainerMerkleTree.Builder treeBuilder = originalTree.toProto().toBuilder();
    ContainerDiffReport diff = new ContainerDiffReport();

    introduceMissingBlocks(treeBuilder, numMissingBlocks, diff);
    introduceMissingChunks(treeBuilder, numMissingChunks, diff);
    introduceCorruptChunks(treeBuilder, numCorruptChunks, diff);
    ContainerProtos.ContainerMerkleTree build = treeBuilder.build();
    return Pair.of(build, diff);
  }

  /**
   * Introduces missing blocks by removing random blocks from the tree.
   */
  private static void introduceMissingBlocks(ContainerProtos.ContainerMerkleTree.Builder treeBuilder,
                                             int numMissingBlocks,
                                             ContainerDiffReport diff) {
    // Set to track unique blocks selected for mismatches
    Set<Integer> selectedBlocks = new HashSet<>();
    Random random = new Random();
    for (int i = 0; i < numMissingBlocks; i++) {
      int randomBlockIndex;
      do {
        randomBlockIndex = random.nextInt(treeBuilder.getBlockMerkleTreeCount());
      } while (selectedBlocks.contains(randomBlockIndex));
      selectedBlocks.add(randomBlockIndex);
      ContainerProtos.BlockMerkleTree blockMerkleTree = treeBuilder.getBlockMerkleTree(randomBlockIndex);
      diff.addMissingBlock(blockMerkleTree);
      treeBuilder.removeBlockMerkleTree(randomBlockIndex);
      treeBuilder.setDataChecksum(random.nextLong());
    }
  }

  /**
   * Introduces missing chunks by removing random chunks from selected blocks.
   */
  private static void introduceMissingChunks(ContainerProtos.ContainerMerkleTree.Builder treeBuilder,
                                             int numMissingChunks,
                                             ContainerDiffReport diff) {
    // Set to track unique blocks selected for mismatches
    Random random = new Random();
    for (int i = 0; i < numMissingChunks; i++) {
      int randomBlockIndex = random.nextInt(treeBuilder.getBlockMerkleTreeCount());

      // Work on the chosen block to remove a random chunk
      ContainerProtos.BlockMerkleTree.Builder blockBuilder = treeBuilder.getBlockMerkleTreeBuilder(randomBlockIndex);
      if (blockBuilder.getChunkMerkleTreeCount() > 0) {
        int randomChunkIndex = random.nextInt(blockBuilder.getChunkMerkleTreeCount());
        ContainerProtos.ChunkMerkleTree chunkMerkleTree = blockBuilder.getChunkMerkleTree(randomChunkIndex);
        diff.addMissingChunk(blockBuilder.getBlockID(), chunkMerkleTree);
        blockBuilder.removeChunkMerkleTree(randomChunkIndex);
        blockBuilder.setDataChecksum(random.nextLong());
        treeBuilder.setDataChecksum(random.nextLong());
      }
    }
  }

  /**
   * Introduces corrupt chunks by altering the checksum and setting them as unhealthy,
   * ensuring each chunk in a block is only selected once for corruption.
   */
  private static void introduceCorruptChunks(ContainerProtos.ContainerMerkleTree.Builder treeBuilder,
                                             int numCorruptChunks,
                                             ContainerDiffReport diff) {
    Map<Integer, Set<Integer>> corruptedChunksByBlock = new HashMap<>();
    Random random = new Random();

    for (int i = 0; i < numCorruptChunks; i++) {
      // Select a random block
      int randomBlockIndex = random.nextInt(treeBuilder.getBlockMerkleTreeCount());
      ContainerProtos.BlockMerkleTree.Builder blockBuilder = treeBuilder.getBlockMerkleTreeBuilder(randomBlockIndex);

      // Ensure each chunk in the block is only corrupted once
      Set<Integer> corruptedChunks = corruptedChunksByBlock.computeIfAbsent(randomBlockIndex, k -> new HashSet<>());
      if (corruptedChunks.size() < blockBuilder.getChunkMerkleTreeCount()) {
        int randomChunkIndex;
        do {
          randomChunkIndex = random.nextInt(blockBuilder.getChunkMerkleTreeCount());
        } while (corruptedChunks.contains(randomChunkIndex));
        corruptedChunks.add(randomChunkIndex);

        // Corrupt the selected chunk
        ContainerProtos.ChunkMerkleTree.Builder chunkBuilder = blockBuilder.getChunkMerkleTreeBuilder(randomChunkIndex);
        diff.addCorruptChunk(blockBuilder.getBlockID(), chunkBuilder.build());
        chunkBuilder.setDataChecksum(chunkBuilder.getDataChecksum() + random.nextInt(1000) + 1);
        chunkBuilder.setChecksumMatches(false);
        blockBuilder.setDataChecksum(random.nextLong());
        treeBuilder.setDataChecksum(random.nextLong());
      }
    }
  }

  public static void assertContainerDiffMatch(ContainerDiffReport expectedDiff,
                                              ContainerDiffReport actualDiff) {
    assertNotNull(expectedDiff, "Expected diff is null");
    assertNotNull(actualDiff, "Actual diff is null");
    assertEquals(expectedDiff.getMissingBlocks().size(), actualDiff.getMissingBlocks().size(),
        "Mismatch in number of missing blocks");
    assertEquals(expectedDiff.getMissingChunks().size(), actualDiff.getMissingChunks().size(),
        "Mismatch in number of missing chunks");
    assertEquals(expectedDiff.getCorruptChunks().size(), actualDiff.getCorruptChunks().size(),
        "Mismatch in number of corrupt chunks");

    List<ContainerProtos.BlockMerkleTree> expectedMissingBlocks = expectedDiff.getMissingBlocks().stream().sorted(
        Comparator.comparing(ContainerProtos.BlockMerkleTree::getBlockID)).collect(Collectors.toList());
    List<ContainerProtos.BlockMerkleTree> actualMissingBlocks = expectedDiff.getMissingBlocks().stream().sorted(
        Comparator.comparing(ContainerProtos.BlockMerkleTree::getBlockID)).collect(Collectors.toList());
    for (int i = 0; i < expectedMissingBlocks.size(); i++) {
      ContainerProtos.BlockMerkleTree expectedBlockMerkleTree = expectedMissingBlocks.get(i);
      ContainerProtos.BlockMerkleTree actualBlockMerkleTree = actualMissingBlocks.get(i);
      assertEquals(expectedBlockMerkleTree.getBlockID(), actualBlockMerkleTree.getBlockID());
      assertEquals(expectedBlockMerkleTree.getChunkMerkleTreeCount(),
          actualBlockMerkleTree.getChunkMerkleTreeCount());
      assertEquals(expectedBlockMerkleTree.getDataChecksum(), actualBlockMerkleTree.getDataChecksum());
      assertEqualsChunkMerkleTree(expectedBlockMerkleTree.getChunkMerkleTreeList(),
          actualBlockMerkleTree.getChunkMerkleTreeList(), expectedBlockMerkleTree.getBlockID());
    }

    // Check missing chunks
    Map<Long, List<ContainerProtos.ChunkMerkleTree>> expectedMissingChunks = expectedDiff.getMissingChunks();
    Map<Long, List<ContainerProtos.ChunkMerkleTree>> actualMissingChunks = actualDiff.getMissingChunks();

    for (Map.Entry<Long, List<ContainerProtos.ChunkMerkleTree>> entry : expectedMissingChunks.entrySet()) {
      Long blockId = entry.getKey();
      List<ContainerProtos.ChunkMerkleTree> expectedChunks = entry.getValue().stream().sorted(
          Comparator.comparing(ContainerProtos.ChunkMerkleTree::getOffset)).collect(Collectors.toList());
      List<ContainerProtos.ChunkMerkleTree> actualChunks = actualMissingChunks.get(blockId).stream().sorted(
          Comparator.comparing(ContainerProtos.ChunkMerkleTree::getOffset)).collect(Collectors.toList());

      assertNotNull(actualChunks, "Missing chunks for block " + blockId + " not found in actual diff");
      assertEquals(expectedChunks.size(), actualChunks.size(),
          "Mismatch in number of missing chunks for block " + blockId);
      assertEqualsChunkMerkleTree(expectedChunks, actualChunks, blockId);
    }

    // Check corrupt chunks
    Map<Long, List<ContainerProtos.ChunkMerkleTree>> expectedCorruptChunks = expectedDiff.getCorruptChunks();
    Map<Long, List<ContainerProtos.ChunkMerkleTree>> actualCorruptChunks = actualDiff.getCorruptChunks();

    for (Map.Entry<Long, List<ContainerProtos.ChunkMerkleTree>> entry : expectedCorruptChunks.entrySet()) {
      Long blockId = entry.getKey();
      List<ContainerProtos.ChunkMerkleTree> expectedChunks = entry.getValue().stream().sorted(
          Comparator.comparing(ContainerProtos.ChunkMerkleTree::getOffset)).collect(Collectors.toList());
      List<ContainerProtos.ChunkMerkleTree> actualChunks = actualCorruptChunks.get(blockId).stream().sorted(
          Comparator.comparing(ContainerProtos.ChunkMerkleTree::getOffset)).collect(Collectors.toList());

      assertNotNull(actualChunks, "Corrupt chunks for block " + blockId + " not found in actual diff");
      assertEquals(expectedChunks.size(), actualChunks.size(),
          "Mismatch in number of corrupt chunks for block " + blockId);
      assertEqualsChunkMerkleTree(expectedChunks, actualChunks, blockId);
    }
  }

  private static void assertEqualsChunkMerkleTree(List<ContainerProtos.ChunkMerkleTree> expectedChunkMerkleTreeList,
                                                  List<ContainerProtos.ChunkMerkleTree> actualChunkMerkleTreeList,
                                                  Long blockId) {
    assertEquals(expectedChunkMerkleTreeList.size(), actualChunkMerkleTreeList.size());
    for (int j = 0; j < expectedChunkMerkleTreeList.size(); j++) {
      ContainerProtos.ChunkMerkleTree expectedChunk = expectedChunkMerkleTreeList.get(j);
      ContainerProtos.ChunkMerkleTree actualChunk = actualChunkMerkleTreeList.get(j);
      assertEquals(expectedChunk.getOffset(), actualChunk.getOffset(), "Mismatch in chunk offset for block "
          + blockId);
      assertEquals(expectedChunk.getDataChecksum(), actualChunk.getDataChecksum(),
          "Mismatch in chunk checksum for block " + blockId);
    }
  }

  /**
   * This function checks whether the container checksum file exists.
   */
  public static boolean containerChecksumFileExists(HddsDatanodeService hddsDatanode, long containerID) {
    OzoneContainer ozoneContainer = hddsDatanode.getDatanodeStateMachine().getContainer();
    Container<?> container = ozoneContainer.getController().getContainer(containerID);
    return ContainerChecksumTreeManager.checksumFileExist(container);
  }

  public static void writeContainerDataTreeProto(ContainerData data, ContainerProtos.ContainerMerkleTree tree)
      throws IOException {
    ContainerProtos.ContainerChecksumInfo checksumInfo = ContainerProtos.ContainerChecksumInfo.newBuilder()
        .setContainerID(data.getContainerID())
        .setContainerMerkleTree(tree).build();
    File checksumFile = getContainerChecksumFile(data);

    try (OutputStream outputStream = Files.newOutputStream(checksumFile.toPath())) {
      checksumInfo.writeTo(outputStream);
    } catch (IOException ex) {
      throw new IOException("Error occurred when writing container merkle tree for containerID "
          + data.getContainerID(), ex);
    }
    data.setDataChecksum(checksumInfo.getContainerMerkleTree().getDataChecksum());
  }
}
